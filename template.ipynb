{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLEASE WRITE THE GITHUB URL BELOW!\n",
    "\n",
    "import csv\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt # from matplot import pyplot as plt 똑같은 의미\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "\n",
    "dataset = pd.read_csv(\"example_datasets/heart.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
      "0      52    1   0       125   212    0        1      168      0      1.0   \n",
      "1      53    1   0       140   203    1        0      155      1      3.1   \n",
      "2      70    1   0       145   174    0        1      125      1      2.6   \n",
      "3      61    1   0       148   203    0        1      161      0      0.0   \n",
      "4      62    0   0       138   294    1        1      106      0      1.9   \n",
      "...   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
      "1020   59    1   1       140   221    0        1      164      1      0.0   \n",
      "1021   60    1   0       125   258    0        0      141      1      2.8   \n",
      "1022   47    1   0       110   275    0        0      118      1      1.0   \n",
      "1023   50    0   0       110   254    0        0      159      0      0.0   \n",
      "1024   54    1   0       120   188    0        1      113      0      1.4   \n",
      "\n",
      "      slope  ca  thal  target  \n",
      "0         2   2     3       0  \n",
      "1         0   0     3       0  \n",
      "2         0   0     3       0  \n",
      "3         2   1     3       0  \n",
      "4         1   3     2       0  \n",
      "...     ...  ..   ...     ...  \n",
      "1020      2   0     2       1  \n",
      "1021      1   1     3       0  \n",
      "1022      1   1     2       0  \n",
      "1023      2   0     2       1  \n",
      "1024      1   1     3       0  \n",
      "\n",
      "[1025 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1025 entries, 0 to 1024\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1025 non-null   int64  \n",
      " 1   sex       1025 non-null   int64  \n",
      " 2   cp        1025 non-null   int64  \n",
      " 3   trestbps  1025 non-null   int64  \n",
      " 4   chol      1025 non-null   int64  \n",
      " 5   fbs       1025 non-null   int64  \n",
      " 6   restecg   1025 non-null   int64  \n",
      " 7   thalach   1025 non-null   int64  \n",
      " 8   exang     1025 non-null   int64  \n",
      " 9   oldpeak   1025 non-null   float64\n",
      " 10  slope     1025 non-null   int64  \n",
      " 11  ca        1025 non-null   int64  \n",
      " 12  thal      1025 non-null   int64  \n",
      " 13  target    1025 non-null   int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 112.2 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target']\n"
     ]
    }
   ],
   "source": [
    "print(list(dataset.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset.keys())-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    526\n",
      "0    499\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(dataset['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499\n"
     ]
    }
   ],
   "source": [
    "target_number = dataset['target']\n",
    "n_class0 =0 \n",
    "for i in range(len(target_number)):\n",
    "    if dataset['target'][i] == 0:\n",
    "        n_class0 +=1\n",
    "print(n_class0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset_path):\n",
    "\tdataset = pd.read_csv(\"heart.csv\")\n",
    "\treturn dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_stat(dataset_df):\n",
    "    n_feats\t = len(dataset.keys())-1\n",
    "    n_class0 = 0 \n",
    "    n_class1 = 0\n",
    "    \n",
    "    for i in range(len(target_number)):\n",
    "        if dataset['target'][i] == 0:\n",
    "            n_class0 += 1\n",
    "        else :\n",
    "            n_class1 += 1\n",
    "            \n",
    "    return n_feats, n_class0, n_class1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset_df, testset_size):\n",
    "\t#To-Do: Implement this function\n",
    "\tx = dataset_df.drop(columns=\"target\", axis = 1)\n",
    "\ty = dataset_df[\"target\"]\n",
    "\n",
    "\tx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = testset_size)\n",
    "\n",
    "\treturn x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(615, 13) (410, 13)\n",
      "(615,) (410,)\n"
     ]
    }
   ],
   "source": [
    "x = dataset.drop(columns=\"target\", axis = 1)\n",
    "y = dataset[\"target\"]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.4)\n",
    "print(x_train.shape, x_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_train_test(x_train, x_test, y_train, y_test):\n",
    "\t#To-Do: Implement this function\n",
    " \ta =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_train_test(x_train, x_test, y_train, y_test):\n",
    "\t#To-Do: Implement this function\n",
    "\ta =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_train_test(x_train, x_test, y_train, y_test):\n",
    "\t#To-Do: Implement this function\n",
    "\ta =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_performances(acc, prec, recall):\n",
    "\t#Do not modify this function!\n",
    "\tprint (\"Accuracy: \", acc)\n",
    "\tprint (\"Precision: \", prec)\n",
    "\tprint (\"Recall: \", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features:  13\n",
      "Number of class 0 data entries:  499\n",
      "Number of class 1 data entries:  526\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '/Users/gimseong-eon/Library/Jupyter/runtime/kernel-6d49c391-0f24-4e56-80e6-066f58961d1a.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/gimseong-eon/Desktop/AutoML/template.ipynb 셀 15\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gimseong-eon/Desktop/AutoML/template.ipynb#X21sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mNumber of class 0 data entries: \u001b[39m\u001b[39m\"\u001b[39m, n_class0)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gimseong-eon/Desktop/AutoML/template.ipynb#X21sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mNumber of class 1 data entries: \u001b[39m\u001b[39m\"\u001b[39m, n_class1)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/gimseong-eon/Desktop/AutoML/template.ipynb#X21sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mSplitting the dataset with the test size of \u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mfloat\u001b[39;49m(sys\u001b[39m.\u001b[39;49margv[\u001b[39m2\u001b[39;49m]))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gimseong-eon/Desktop/AutoML/template.ipynb#X21sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m x_train, x_test, y_train, y_test \u001b[39m=\u001b[39m split_dataset(data_df, \u001b[39mfloat\u001b[39m(sys\u001b[39m.\u001b[39margv[\u001b[39m2\u001b[39m]))\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '/Users/gimseong-eon/Library/Jupyter/runtime/kernel-6d49c391-0f24-4e56-80e6-066f58961d1a.json'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\t#Do not modify the main script!\n",
    "\tdata_path = sys.argv[1]\n",
    "\tdata_df = load_dataset(data_path)\n",
    "\n",
    "\tn_feats, n_class0, n_class1 = dataset_stat(data_df)\n",
    "\tprint (\"Number of features: \", n_feats)\n",
    "\tprint (\"Number of class 0 data entries: \", n_class0)\n",
    "\tprint (\"Number of class 1 data entries: \", n_class1)\n",
    "\n",
    "\tprint (\"\\nSplitting the dataset with the test size of \", float(sys.argv[2]))\n",
    "\tx_train, x_test, y_train, y_test = split_dataset(data_df, float(sys.argv[2]))\n",
    "\n",
    "\t# acc, prec, recall = decision_tree_train_test(x_train, x_test, y_train, y_test)\n",
    "\t# print (\"\\nDecision Tree Performances\")\n",
    "\t# print_performances(acc, prec, recall)\n",
    "\n",
    "\t# acc, prec, recall = random_forest_train_test(x_train, x_test, y_train, y_test)\n",
    "\t# print (\"\\nRandom Forest Performances\")\n",
    "\t# print_performances(acc, prec, recall)\n",
    "\n",
    "\t# acc, prec, recall = svm_train_test(x_train, x_test, y_train, y_test)\n",
    "\t# print (\"\\nSVM Performances\")\n",
    "\t# print_performances(acc, prec, recall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
